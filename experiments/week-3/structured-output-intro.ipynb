{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be384961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "import instructor \n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d85526",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "you are a helpful assistant that can answer questions \n",
    "and help with tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "453dccc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CWRL3dPpx9TuuvyJhEFrtLyy8rZRR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='How can I assist you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761847621, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=7, prompt_tokens=23, total_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client_OAI = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb7be6",
   "metadata": {},
   "source": [
    "## Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29b218ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(openai.OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2906e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGGenerationResponse(BaseModel):\n",
    "    answer: str = Field(description=\"Answer to the user's question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f27328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The Grand Canyon is estimated to be around 5 to 6 million years old, formed by the erosion of the Colorado River cutting through layers of rock over millions of years.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, raw_response = client.chat.completions.create_with_completion(\\\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "    response_model = RAGGenerationResponse\n",
    ")\n",
    "response.model_dump()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c69200b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CWRHdhH46413LlQxLoTvMVqX6G6Pu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_nePVRtFpjZLSoX05AbawlLzB', function=Function(arguments='{\"answer\":\"Can you tell me about the significance of the animal spirit in Native American cultures?\"}', name='RAGGenerationResponse'), type='function')]))], created=1761847409, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=20, prompt_tokens=90, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa44b6",
   "metadata": {},
   "source": [
    "## RAG with instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87a85544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "def retrieve_data(query, qdrant_client, k=5):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-00\",\n",
    "        query=query_embedding,\n",
    "        limit=k,\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_images = []\n",
    "    retrieved_metadata = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        similarity_scores.append(result.score)\n",
    "        \n",
    "        # Extract image URL if available\n",
    "        image_url = result.payload.get(\"image\", None)\n",
    "        retrieved_images.append(image_url)\n",
    "        \n",
    "        # Extract other metadata\n",
    "        metadata = {\n",
    "            \"parent_asin\": result.payload.get(\"parent_asin\"),\n",
    "            \"price\": result.payload.get(\"price\"),\n",
    "            \"average_rating\": result.payload.get(\"average_rating\"),\n",
    "            \"rating_number\": result.payload.get(\"rating_number\"),\n",
    "            \"store\": result.payload.get(\"store\"),\n",
    "            \"video\": result.payload.get(\"video\"),\n",
    "            \"image\": result.payload.get(\"image\")\n",
    "        }\n",
    "        retrieved_metadata.append(metadata)\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context_ids\": retrieved_context_ids,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"similarity_scores\": similarity_scores,\n",
    "        \"retrieved_images\": retrieved_images,\n",
    "        \"retrieved_metadata\": retrieved_metadata,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_context(context):\n",
    "\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk in zip(context[\"retrieved_context_ids\"], context[\"retrieved_context\"]):\n",
    "        formatted_context += f\"- {id}: {chunk}\\n\"\n",
    "\n",
    "    return formatted_context\n",
    "\n",
    "\n",
    "\n",
    "def build_prompt(preprocessed_context, question):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of context.\n",
    "\n",
    "Instructtions:\n",
    "- You need to answer the question based on the provided context only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "\n",
    "Context:\n",
    "{preprocessed_context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer(prompt):\n",
    "\n",
    "    response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=0.5,\n",
    "        response_model=RAGGenerationResponse\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "def rag_pipeline(question, qdrant_client, top_k=5):\n",
    "\n",
    "    retrieved_context = retrieve_data(question, qdrant_client, top_k)\n",
    "    preprocessed_context = process_context(retrieved_context)\n",
    "    prompt = build_prompt(preprocessed_context, question)\n",
    "    answer = generate_answer(prompt)\n",
    "\n",
    "    # Filter out None values from images and create a list of valid image URLs\n",
    "    valid_images = [img for img in retrieved_context[\"retrieved_images\"] if img is not None]\n",
    "    \n",
    "    # Filter metadata to only include items with images\n",
    "    valid_metadata = [meta for meta, img in zip(retrieved_context[\"retrieved_metadata\"], retrieved_context[\"retrieved_images\"]) if img is not None]\n",
    "\n",
    "    final_result = {\n",
    "        \"answer\": answer.answer,\n",
    "        \"question\": question,\n",
    "        \"retrieved_context_ids\": retrieved_context[\"retrieved_context_ids\"],\n",
    "        \"retrieved_context\": retrieved_context[\"retrieved_context\"],\n",
    "        \"similarity_scores\": retrieved_context[\"similarity_scores\"],\n",
    "        \"images\": valid_images,\n",
    "        \"product_metadata\": valid_metadata\n",
    "    }\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9642d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_pipeline(\"What is the price of the product?\", qdrant_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f163d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The available products do not provide information about the price of the products.',\n",
       " 'question': 'What is the price of the product?',\n",
       " 'retrieved_context_ids': ['B09QM776N9',\n",
       "  'B0BLRGWXQL',\n",
       "  'B09VN35T1M',\n",
       "  'B09RLSF7B2',\n",
       "  'B0C649RHHN'],\n",
       " 'retrieved_context': [\"Bruno Marc Men's Fashion Sneakers Casual Comfort Canvas Skate Shoes 100% Canvas Imported Rubber sole Premium canvas upper is comfortable and soft to the touch and also provide advanced upper stitching workmanship make the men shoes durable enough to last a long time Soft inner material can provide a comfortable foot environment and prevent feet from grinding MEMORY FOAM INSOLE: A memory foam insole provides cushioning and reduces fatigue. The honeycomb design on the bottom of the insole keeps your feet dry and comfortable all day long Rubber-plastic foam outsole is not only soft and lightweight, but also has the characteristics of rubber anti-skid and wear-resistant. Three-dimensional non-slip textured sole can enhance the grip, so you don't have to worry about the soles of your feet slipping  P a c k a g e   D i m e n s i o n s :   1 3 . 8 2   x   7 . 6   x   4 . 6 9   i n c h e s ;   1 . 7 6   P o u n d s .   I t e m   m o d e l   n u m b e r :   B 2 2 5 - 2 A 1 A J 0 2 - H 4 0 M H - 1 5 7 1 8 1 2 4 8 1 2 2 .   D e p a r t m e n t :   m e n s .   D a t e   F i r s t   A v a i l a b l e :   J a n u a r y   1 8 ,   2 0 2 2 Clothing, Shoes & Jewelry Men Shoes Fashion Sneakers\",\n",
       "  \"Daily Ritual Women's Jersey Relaxed-Fit Sleeveless Mock Neck Shirt 95% Rayon (Lenzing Ecovero Viscose), 5% Elastane Imported Pull On closure Machine Wash A wardrobe staple, this Jersey Sleeveless Boxy Mock-Neck Shirt This casual wardrobe-essential tee features a lightweight fit for comfortable everyday wear This casual wardrobe-essential tee features a lightweight fit for comfortable everyday wear Made with an Ecovero Viscose blend. Ecovero Viscose is made from renewable wood sources and contains a unique identification marker that ensures traceability and trust at all stages of production, from fiber to fabric. An Amazon Brand - A wardrobe staple, this Jersey Sleeveless Boxy Mock-Neck Shirt I t e m   m o d e l   n u m b e r :   D R 1 8 1 9 3 6 _ S .   D e p a r t m e n t :   W o m e n s .   D a t e   F i r s t   A v a i l a b l e :   N o v e m b e r   8 ,   2 0 2 2 .   M a n u f a c t u r e r :   D a i l y   R i t u a l Clothing, Shoes & Jewelry Women Clothing Tops, Tees & Blouses T-Shirts\",\n",
       "  \"New Balance Men's 4040 V4 Turf Baseball Shoe 100% Synthetic Nubuck Imported Rubber sole Batter up with the versatile Turf 4040v4. Shoe features a one piece nubby outsole to help you perform on a variety of surfaces. Trainer is also made with durable materials designed to move with you – so you can make the big plays. High traction nubby turf outsole Probalance sole platform Synthetic upper Batter up with the versatile Turf 4040v4. Shoe features a one piece nubby outsole to help you perform on a variety of surfaces. Trainer is also made with durable materials designed to move with you – so you can make the big plays. New Balance, is dedicated to helping athletes achieve their goals. It's been their mission for more than a century. It's why they don't spend money on celebrity endorsements. They spend it on research and development. It's why they don't design products to fit an image. They design them to fit. New Balance is driven to make the finest shoes for the same reason athletes lace them up: to achieve the very best. I t e m   m o d e l   n u m b e r :   T 4 0 4 0 T N 4 .   D e p a r t m e n t :   m e n s .   D a t e   F i r s t   A v a i l a b l e :   M a r c h   1 5 ,   2 0 2 2 .   M a n u f a c t u r e r :   N e w   B a l a n c e Clothing, Shoes & Jewelry Men Shoes Athletic Team Sports Baseball & Softball\",\n",
       "  'CUSHIONAIRE Women\\'s Pippin thong platform sandal with +Memory Foam Rubber sole Heel measures approximately 2 inches\" Premium Vegan Leather upper Memory Foam Insoles Soft, Light, and Flexible outsole 2 Inch platform Step into these fashionable and comfortable platform sandals to carry you through your day with ease. These sandals feature a soft thong upper and Memory foam insoles. P a c k a g e   D i m e n s i o n s :   1 1 . 5   x   7   x   4 . 5   i n c h e s ;   1 . 5 1   P o u n d s .   D e p a r t m e n t :   W o m e n s .   D a t e   F i r s t   A v a i l a b l e :   J a n u a r y   3 1 ,   2 0 2 2 Clothing, Shoes & Jewelry Women Shoes Sandals Platforms & Wedges',\n",
       "  \"POLO RALPH LAUREN Men's Train 90 Sneaker Imported Rubber sole Shaft measures approximately low-top from arch Rounded toe Lace-up front Inspired by classic running shoes from The late 1970s, the train 90 sneaker is designed with a low profile and an iconic percent-wing patch from polo’s stadium collection. I t e m   m o d e l   n u m b e r :   8 0 9 7 3 6 2 5 8 0 0 6 .   D e p a r t m e n t :   m e n s .   D a t e   F i r s t   A v a i l a b l e :   M a y   2 4 ,   2 0 2 3 .   M a n u f a c t u r e r :   P o l o   R a l p h   L a u r e n Clothing, Shoes & Jewelry Men Shoes Fashion Sneakers\"],\n",
       " 'similarity_scores': [0.16212258,\n",
       "  0.16108307,\n",
       "  0.15953815,\n",
       "  0.15749866,\n",
       "  0.15728536],\n",
       " 'images': ['https://m.media-amazon.com/images/I/41cKhtvOwfL._AC_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/51ZtXIqoKAL._AC_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/416GNuV6J2L._AC_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/31pyoYzPxFL._AC_.jpg',\n",
       "  'https://m.media-amazon.com/images/I/41-FwXqsocL._AC_.jpg'],\n",
       " 'product_metadata': [{'parent_asin': 'B09QM776N9',\n",
       "   'price': None,\n",
       "   'average_rating': 4.3,\n",
       "   'rating_number': 580,\n",
       "   'store': 'Bruno Marc',\n",
       "   'video': 'https://www.amazon.com/vdp/08c000f16bde4a318ed54dc0d50b76e0?ref=dp_vse_rvc_0',\n",
       "   'image': 'https://m.media-amazon.com/images/I/41cKhtvOwfL._AC_.jpg'},\n",
       "  {'parent_asin': 'B0BLRGWXQL',\n",
       "   'price': 12.72,\n",
       "   'average_rating': 4.2,\n",
       "   'rating_number': 188,\n",
       "   'store': 'Daily Ritual',\n",
       "   'video': '',\n",
       "   'image': 'https://m.media-amazon.com/images/I/51ZtXIqoKAL._AC_.jpg'},\n",
       "  {'parent_asin': 'B09VN35T1M',\n",
       "   'price': None,\n",
       "   'average_rating': 4.5,\n",
       "   'rating_number': 124,\n",
       "   'store': 'New Balance',\n",
       "   'video': '',\n",
       "   'image': 'https://m.media-amazon.com/images/I/416GNuV6J2L._AC_.jpg'},\n",
       "  {'parent_asin': 'B09RLSF7B2',\n",
       "   'price': 34.99,\n",
       "   'average_rating': 4.1,\n",
       "   'rating_number': 483,\n",
       "   'store': 'CUSHIONAIRE',\n",
       "   'video': 'https://www.amazon.com/vdp/04386e9b4a584ead8728bd0b0ff19a46?ref=dp_vse_rvc_0',\n",
       "   'image': 'https://m.media-amazon.com/images/I/31pyoYzPxFL._AC_.jpg'},\n",
       "  {'parent_asin': 'B0C649RHHN',\n",
       "   'price': 97.56,\n",
       "   'average_rating': 4.6,\n",
       "   'rating_number': 118,\n",
       "   'store': 'POLO RALPH LAUREN',\n",
       "   'video': '',\n",
       "   'image': 'https://m.media-amazon.com/images/I/41-FwXqsocL._AC_.jpg'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
